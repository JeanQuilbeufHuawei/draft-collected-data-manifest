<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd">
<?xml-stylesheet type="text/xsl" href="rfc2629.xslt" ?>
<?rfc toc="yes"?>
<?rfc tocompact="yes"?>
<?rfc tocdepth="4"?>
<?rfc tocindent="yes"?>
<?rfc symrefs="yes"?>
<?rfc sortrefs="yes"?>
<?rfc comments="yes"?>
<?rfc inline="yes"?>
<?rfc compact="yes"?>
<?rfc subcompact="no"?>
<rfc category="std" ipr="trust200902" docName="draft-claise-opsawg-collected-data-manifest-06">
  <front>
    <title abbrev="Telemetry Data Manifest">A Data Manifest for Contextualized Telemetry Data</title>
    <author fullname="Benoit Claise" initials="B" surname="Claise">
      <organization>Huawei</organization>
      <address>
        <email>benoit.claise@huawei.com</email>
      </address>
    </author>
    <author fullname="Jean Quilbeuf" initials="J" surname="Quilbeuf ">
      <organization>Huawei</organization>
      <address>
        <email>jean.quilbeuf@huawei.com</email>
      </address>
    </author>
    <author fullname="Diego R. Lopez" initials="D" surname="Lopez ">
      <organization>Telefonica I+D</organization>
      <address>
        <postal>
          <street>Don Ramon de la Cruz, 82</street>
          <city>Madrid  28006</city>
          <country>Spain</country>
        </postal>
        <email>diego.r.lopez@telefonica.com</email>
      </address>
    </author>
    <author fullname="Ignacio Dominguez" initials="I" surname="Dominguez">
      <organization>Telefonica I+D</organization>
      <address>
        <postal>
          <street>Ronda de la Comunicacion, S/N</street>
          <city>Madrid  28050</city>
          <country>Spain</country>
        </postal>
        <email>ignacio.dominguezmartinez@telefonica.com</email>
      </address>
    </author>
    <author fullname="Thomas Graf" initials="T. " surname="Graf">
      <organization>Swisscom</organization>
      <address>
        <postal>
          <street>Binzring 17</street>
          <city>Zurich</city>
          <code>8045</code>
          <country>Switzerland</country>
        </postal>
        <email>thomas.graf@swisscom.com</email>
      </address>
    </author>
    <date/>
    <area>OPS</area>
    <workgroup>OPSAWG</workgroup>
    <abstract>
      <t>
      Network elements use Model-driven Telemetry, and in particular YANG-Push, to continuously stream information, including both counters and state information.
		  This document documents the metadata that ensure that the collected data can be interpreted correctly.
		  This document specifies the Data Manifest, composed of two YANG data models (the Platform Manifest and the Data Collection Manifest.) The Data Manifest must be streamed and stored along with the data, up to the collection and analytics system in order to keep the collected data fully exploitable by the data scientists.
      </t>
    </abstract>
  </front>
  <middle>
    <section anchor="intro" title="Introduction">
      <t>
        Network elements use Model-driven Telemetry (MDT), and in particular YANG-Push <xref target="RFC8641"/>, to continuously stream information, including both counters and state information.
      </t>
      <t>
        This document specifies what needs to be kept as metadata (i.e., the Data Manifest) to ensure that the collected data can still be interpreted correctly throughout the collection and network analytics toolchain. When streaming YANG-structured data with YANG-Push [RFC8641], there is a semantic definition in the corresponding YANG module definition. This is the semantic information for the collected objects: While this semantic is absolutely required to correctly decode and interpret the data, understanding the network element and collection environment contexts information is equally important to interpret the data.
      </t>
      <t>
        This document proposes the Data Manifest, which is composed of two YANG data models, namely, the Platform Manifest and the Data Collection Manifest, in order to keep the collected data exploitable by the data scientists.
      </t>
      <t>
        The Platform Manifest contains information characterizing the platform streaming the telemetry information, while the the Data Collection Manifest contains the required information to characterize how and when the telemetry information was metered.
      </t>
      <t>         
        The two proposed YANG modules in the Data Manifest do not expose many new information but rather define what should be exposed by a platform streaming telemetry. Some related YANG modules have been specified to retrieve the platform capabilities:
        <list style="symbols">
          <t>
            The IETF YANG Library <xref target="RFC8525"/>.
          </t>
          <t>
            YANG Modules Describing Capabilities for Systems and Datastore Update Notifications <xref target="RFC9196"/> for the platform capabilities regarding the production and export of telemetry data.
          </t>
          <t>
            <xref target="I-D.claise-netconf-metadata-for-collection"/>, which is based on the previous draft to define the optimal settings to stream specific items (i.e., per path).
          </t>
        </list>
        These related YANG modules are important to discover the capabilities before applying the telemetry configuration (such as on-change). Some of their content is part of the context for the streamed data.
      </t>
      <t>
        We first present the module for the Platform Manifest in Section 3 and then the module for the Data Collection Manifest in Section 4. The full Data Manifest is obtained by combining these two modules. We explain in Section 5 how the Data Manifest can be retrieved and how collected data is mapped to the Data Manifest.
      </t>

      <section anchor="use-cases" title="Use Cases">
    
         <section anchor="network-analytics" title="Network Analytics">
           <t>
            Streamed information from network elements is used for network analytics, incident detections, and in the end closed-loop automation. This streamed data can be stored in a database (sometimes called a big data lake) for further analysis.
          </t>
          <t>         
            As an example, a database could store a time series representing the evolution of a specific counter collected from a network element. When analyzing the data, the network operator/data scientist must understand the context information for these data:
            <list style="symbols">
            <t>
              This object definition in the YANG model.
            </t>
            <t>
              The network element specific vendor, platform, and OS.
            </t>
            <t>
              The collection parameters.
            </t>
            </list>
          </t>
           <t>
              Characterizing the source used for producing the data (vendor, platform, and OS) is useful to complement the data.  As an example, knowing the exact data source software specification might reveal a particularity in the observed data, explained by a specific bug, a specific bug fix, or simply a particular specific behavior.  This is also necessary to ensure the reliability of the collected data. On top of that, in particular for YANG-Push [RFC8641], it is crucial to know the set of YANG modules supported by the platform, along with their deviations. In some cases, there might even be some backwards incompatible changes in native modules between one OS version to the next one.  This information is captured by the proposed Platform Manifest.
          </t>
           <t>
              From a collection parameters point of view, the data scientists analyzing the collected data must know that the counter was requested from the network element as on-change or at specific cadence. Indeed, an on-change collection explains why there is a single value as opposed to a time series. In case of periodic collection, this exact cadence might not be observable in the time series. Indeed, this time series might report some values as 0 or might even omit some values. The reason for this behavior might be diverse: the network element was under stress, with a too small observation period, compared to the minimum-observed-period [I-D.claise-netconf-metadata-for-collection]. Again, knowing the conditions under which the counter was collected and streamed (along with the platform details) help drawing the right conclusions. As an example, taking into account the value of 0 might lead to a wrong conclusion that the counter dropped to zero. This document specifies the Data Collection Manifest, which contains the required information to characterize how and when the telemetry information was metered.
          </t>
           <t>
              The goal of the current document is to define what needs to be kept as metadata (i.e., the Data Manifest) to ensure that the collected data can still be interpreted correctly. 
          </t>
         </section>

         <section anchor="new-device-onboarding" title="New Device Onboarding">
           <t>
              When a new device is onboarded,  operators must make sure that the new device streams data with YANG-Push, that the telemetry data is the right ones, and that the data is correctly ingested in the collection system,  and finally that the data can be analyzed (compared with other similar devices). For the last point, the Data Manifiest, which must be linked to the data up to the collection and analytics system, contains all the relevant information.
          </t>
         </section>

        <section anchor="data-mesh-principles-in-networking" title="Data Mesh Principles in Networking">
          <t>         
             The concept behind the data mesh [https://www.datamesh-architecture.com/] are:
            <list style="symbols">
            <t>
              Principle of Domain Ownership: Architecturally and organizationally align business, technology, and analytical data, following the line of responsibility. Here, the Data Mesh principles adopt the boundary of bounded context to individual data products where each domain is responsible for (and owns) its data and models.
            </t>
            <t>
              Principle of Data as a Product: The “Domain” owners are responsible to provide the data in useful way (discoverable through a catalog, addressable with a permanent and unique address, understandable with well defined semantics, trustworthy and truthful, self-describing for easy consumption, interoperable by supporting standards, secure, self-contained, etc.) and should treat consumers of that data as customers. It requires and relies on the “Domain Ownership” principle.
            </t>
            <t>
              Principle of Self-serve Data Platform: This fosters the sharing of cross-domain data in order to create extra value.
            </t>
            <t>
              Principle of Federated Computational Governance: Describes the operating model and approach to establishing global policies across a mesh of data products. 
            </t>
            </list>
          </t>
           <t>
              The most relevant concept for this document is the "Data as a Product"principle. The Data Manifest fulfills this principle as the two YANG data models, Platform Manifest and the Data Collection Manifest, along with the data, provide all the necessary information in a self-describing way for easy consumption.
          </t>
         </section>

      </section>
    </section>

    <section title="Terminology" anchor="terminology">
      <t>
        The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL
        NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT RECOMMENDED",
        "MAY", and "OPTIONAL" in this document are to be interpreted as
        described in BCP 14 <xref target="RFC2119"/> <xref target="RFC8174"/>
        when, and only when, they appear in all capitals, as shown here.
      </t>
      <t>
        Data Manifest: all the necessary data required to interpret the telemetry information.
      </t>
      <t>
        Platform Manifest: part of the Data Manifest that completely characterizes the platform producing the telemetry information
      </t>
      <t>
        Data Collection Manifest: part of the Data Manifest that completely characterizes how and when the telemetry information was metered.
      </t>
    </section>
    <section anchor="platform-manifest" title="Platform Manifest">
        <section anchor="platform-manifest-model-tree" title="Overview of the Model">
        <t>
          <xref target="platform-manifest-tree"/> contains the YANG tree diagram <xref target="RFC8340"/> of the ietf-platform-manifest module.
            <figure anchor="platform-manifest-tree" title="YANG tree diagram for ietf-platform-manifest module">
              <artwork><![CDATA[
{{platform_manifest_tree}}
                ]]></artwork>
            </figure>
        </t>

          <t>
            The Platform Manifest is identified by a set of parameters ('name', 'software-version', 'software-flavor', 'os-version', 'os-type') that are aligned with the YANG Catalog www.yangcatalog.org <xref target="I-D.clacla-netmod-model-catalog"/> so that the YANG Catalog could be used to retrieve the YANG modules a posteriori.
            The vendor of the platform can be identified via its name 'vendor' or its PEN number 'vendor-pen', as described in <xref target="RFC9371"/>.
          </t>
          <t>
            The Platform Manifest also includes the contents of the YANG Library <xref target="RFC8525"/>.
            That module set is particularly useful to define the paths, as they are based on module names.
            Similarly, this module defines the available datastores, which can be referred to from the Data Manifest, if necessary.
            If supported by the platform, fetching metrics from a specific datastore could enable some specific use cases: monitoring configuration before it is committed, comparing between the configuration and operational datastore.
          </t>
        </section>
      <section anchor="platform-manifest-model" title="YANG module ietf-platform-manifest">
        <t>
          &lt;CODE BEGINS&gt;
          <vspace/> <!-- force filename on a single line, needed for xym -->
          file "ietf-platform-manifest@2021-10-15.yang"
        </t>
        <figure>
          <artwork><![CDATA[
{{platform_manifest_yang}}
            ]]></artwork>
        </figure>
        <t>&lt;CODE ENDS&gt;</t>
      </section>
    </section>

     <section anchor="data-collection-manifest" title="Data Collection Manifest">
        <section anchor="model-tree" title="Overview of the Model">
          <t>
            <xref target="data-collection-manifest-tree"/> contains the YANG tree diagram <xref target="RFC8340"/> of the ietf-data-collection-manifest module.
            <figure anchor="data-collection-manifest-tree" title="YANG tree diagram for ietf-data-collection-manifest module">
              <artwork><![CDATA[
{{data_collection_manifest_tree}}
                ]]></artwork>
            </figure>
          </t>
          <t>
            The data-collection container contains the information related to YANG-Push individual items collection.
          </t>
          <t>
            The YANG-Push MDT collection is organized in subscriptions.
            A given collector can subscribe to one ore more subscriptions that usually contain a list of paths.
            Such a collector only needs the Data Manifest for subscriptions it subscribed to.
            The Data Manifest for MDT is organized by subscriptions as well so that a collector can select only its subscriptions.
          </t>
          <t>
            We now have a chicken-and-egg issue if the collector collects the Data Manifest via MDT and wants the Data Manifest
            for the Data Manifest subscription. First, the collector will collect the actual paths that it needs in subscription A. Once it has the subscription id
            for A, it will need an additional subscription B for the Data Manifest of paths in A. Then, it would need another subscription C to fetch the Data Manifest for the
            subscription B and so on... A possible solution would be adding in the "mdt" container an additional list in that contains the Data Manifest for every
            path that is a Data Manifest. By including that list in subscription B, the collector would have the information about subscription B here.
          </t>
          <t>
            The "datastore" leaf of the subscription container specifies from which datastore the YANG paths are streamed.
          </t>
          <t>
            Within a given collection subscription, the granularity of the collection is defined by the path.
            Note that all network elements do not support an arbitrary granularity up to the leaf, usually for performance reasons.
            Each path currently collected by the platform should show up in the mdt-path-data-manifest list.
          </t>
          <t>
            For each path, the collection context must be specified including:
            <list style="symbols">
              <t> 'on-change': when set to true, an update is sent as soon as and only when a value changes. This is also known as Event-Driven Telemetry (EDT). When set to false, the values are sent regularly. </t>
              <t> 'suppress-redundancy' (only when 'on-change' is false): reduce bandwidth usage by sending a regular update only if the value is different from the previous update.</t>
              <t> 'requested-period' (only when 'on-change' is false): period between two updates requested by the client for this path</t>
              <t> 'actual-period' (only when 'on-change 'is false): actual period retained by the platform between two updates. That period could be larger than the requested one as the router can adjust it for performance reasons.</t>
            </list>
          </t>
          <t>
            This information is crucial to understand the collected values. For instance, the 'on-change' and 'suppress-redundancy' options, if set, might remove a lot of messages from the database because values are sent only when there is a change.
          </t>
      </section>
      <section anchor="module-code" title="YANG module ietf-data-collection-manifest">
        <t>&lt;CODE BEGINS&gt; file "ietf-data-collection-manifest@2021-10-15.yang"</t>
        <figure>
          <artwork><![CDATA[
{{data_collection_manifest_yang}}
    ]]></artwork>
        </figure>
        <t>&lt;CODE ENDS&gt;</t>
      </section>
    </section>
    <section anchor="mapping" title="Data Manifest and the Collected Data">
      <section anchor="collecting_dm" title="Collecting the Data Manifest">
      <t>
          The Data Manifest MUST be streamed and stored along with the collected data.
          In case the collected data are moved to a different place (typically a database), the Data Manifest MUST follow the collected data.
          This can render the collected data unusable if that context is lost, for instance when the data is stored without the relevant information.
          The Data Manifest MUST be updated when the Data Manifest information changes, for example, when a router is upgraded, when a new telemetry subscription is configured, or when the telemetry subscription parameters change.
      </t>
       <t>
          The collected data should be mapped to the Data Manifest. Since the Data Manifest will not change as frequently as the collected data itself, it makes sense to map several data to the same Data Manifest. Somehow, the collected data must include a metadata pointing to the corresponding Data Manifest. In case of Data Manifest change, the collection system should keep the respective Data Manifest even with old data, and not assumed that the latest Data Manifest is valid for the entire time series.

       </t>
       <t>
          The Platform Manifest is likely to remain the same until the platform is updated. Thus, the Platform Manifest only needs to be collected once per streaming session and updated after a platform reboot.
       </t>
        <t>
          As this draft specifically focuses on giving context on data collected via streamed telemetry, we can assume that a streaming telemetry system is available.
          Retrieving the Data Collection Manifest and Platform Manifest can be done either by reusing that streaming telemetry system (in-band) or using another system (out-of-band), for instance by adding headers or saving manifests into a YANG instace file <xref target="RFC9195"/>.
        </t>
        <t>
          We propose to reuse the existing telemetry system (in-band approach) in order to lower the efforts for implementing this draft.
          To enable a platform supporting streaming telemetry to also support the Data Manifest, it is sufficient that this platform supports
          the models from <xref target="platform-manifest"/> and <xref target="data-collection-manifest"/>.
          Recall that each type of manifest has its own rough frequency update, i.e. at reboot for the Platform Manifest and at new subscription or CPU load variation for the Data Collection Manifest.
          The Data Manifest MUST be streamed with the YANG-Push on-change feature <xref target="RFC8641"/> (also called event-driven telemetry).
        </t>
      </section>

      <section anchor="mapping_dm" title="Mapping Collected Data to the Data Manifest">
        <t>
             With MDT, a particular datapoint is always associated to a path that is itself part of a subscription.
             In order to enable a posteriori retrieval of the Data Manifest associated to a datapoint, the collector must:
             <list style="symbols">
                 <t>Keep the path in the metadata of the collected values</t>
                 <t>Collect as well the Data Manifest for the subscription and path associated to the datapoint.</t>
             </list>
             With this information, to retrieve the Data Manifest from the datapoint, the following happens:
             <list style="symbols">
                 <t>The path is retrieved from the datapoint metadata</t>
                 <t>The Data Manifest for that path is retrieved by looking up on the collected Data Manifest.</t>
             </list>
         </t>
         <t>
             In that scenario, the reliability of the collection of the Data Manifest is the same as the reliability of the data collection itself, since the Data Manifest is like any other data.
             For telemetry based on gRPC for instance, a disconnection to the server would be detected as the HTTP connection would fail.
         </t>
      </section>

      <section anchor="operational-considerations" title="Operational Considerations">
         <t>
             It is expected that the Data Manifest is streamed directly from the network equipment, along with YANG-Push [RFC8641] data. However, if the network element streaming telemetry does not support yet the YANG modules from the Data Manifest specified in this document, the telemetry collector could populate the Data Manifest from available information collected from the platform. However, this option requires efforts on the telemetry collector side, as the information gathered in the Data Manifest proposed in this document could be scattered among various standard and vendor- specific YANG modules [RFC8199], that depend on the platform. 
         </t>
         <t>
             That Data Manifest should be kept and available even if the source platform is not accessible (from the collection system), or if the platform has been updated (new operating system or new configuration). The Platform Manifest is "pretty" stable and should change only when the platform is updated or patched. On the other hand, the Data Collection Manifest is likely to change each time a new YANG-Push subscription [RFC8641] is requested and might even change if the platform load increases and collection periods are updated. To separate these two parts, we enclose each of them in its own module. 
         </t>
      </section>
    </section>
    <section anchor="example" title="Example">
      <t> Below is an example of a Data Collection Manifest file:</t>
      <t>&lt;CODE BEGINS&gt; file "ietf-data-collection-manifest@2021-10-15.yang"</t>
      <figure>
        <artwork><![CDATA[
{{data_collection_manifest_example}}
  ]]></artwork>
      </figure>
      <t>&lt;CODE ENDS&gt;</t>
      <t>
        The file above contains the Data Collection Manifest for paths collected in the subscription with id 4242.
        The requested period for both path is this subscription was 100ms, however the status of the interface could only be collected every 10s.
      </t>

    </section>
    <section anchor="security" title="Security Considerations">
      <t>
        As we are reusing an existing telemetry system, the security considerations lies with the new content divulged in the new manifests.
        Appropriate access control must be associated to the corresponding leafs and containers.
      </t>
    </section>
    <section anchor="iana" title="IANA Considerations">
      <t>
        This document includes no request to IANA.
      </t>
    </section>
    <section title="Contributors">
    </section>
    <section title="Open Issues">
      <t>
        <list style="symbols">
          <t>
            Do we want to handle the absence of values, i.e. add information about missed collection or errors in the collection context ? It could also explain why some values are missing. On the other hand, this might also be out scope.
          </t>
          <t>
            Align the terms with the YANG Push specifications. Ex: path to subscription (TBC)
          </t>
          <t>
            Regarding the inclusion of ietf-yang-library in our module, do we want to include as well the changes from ietf-yang-library-revisions? What if other information are present in the yang-library from the platform? Should we use a YANG mount to capture them as well (they would not be captured with our use of the main yang-library grouping).
          </t>
          <t>
            Henk: how does this interact with SBOM effort?
          </t>
          <t>
            Eliot: important to give integrity of the information a lot of thought. Threat model to be considered.
          </t>
        </list>
      </t>
    </section>
  </middle>
  <back>
    <references title="Normative References">
      <?rfc include="reference.RFC.2119"?>
      <?rfc include="reference.RFC.8174"?>
      <?rfc include="reference.RFC.8340"?>
      <?rfc include="reference.RFC.8525"?>
      <?rfc include="reference.RFC.8641"?>
      <?rfc include="reference.RFC.9195"?>
    </references>
    <references title="Informative References">
      <?rfc include="reference.I-D.draft-clacla-netmod-model-catalog-03"?>
      <?rfc include="reference.I-D.draft-claise-netconf-metadata-for-collection-02"?>
      <?rfc include="reference.RFC.8199"?>
      <?rfc include="reference.RFC.8343"?>
      <?rfc include="reference.RFC.9196"?>
      <reference anchor="RFC9371">
        <front>
          <title>Change to include when in ietf database</title>
          <author></author>
          <date/>
        </front>
      </reference>
      <reference anchor="I-D.tgraf-netconf-notif-sequencing" target="https://github.com/network-analytics/draft-tgraf-netconf-notif-sequencing">
        <front>
          <title>Change to include when in ietf database</title>
          <author />
          <date />
        </front>
      </reference>
    </references>
    <?rfc needLines="100"?>
    <section title="Example of use based on MDT">
      <t>
        In this example, the goal is to collect the administrative status and number of received bytes for the interfaces of a fictional ACME device, and store the result in a Influx database.
        The metrics are collected via MDT, which is configured by specifying their paths and when they should be collected (polling period or on-change).
        More precisely, we want collect "ietf-interfaces:interfaces/interface/enabled" on every change and "ietf-interfaces:interfaces/interface/statistics/in-octets" every 100 milliseconds.
        The paths here are referring to the YANG module from <xref target="RFC8343"/>.
        The configuration of MDT is out of scope for this document, we assume that both paths above are configured in the same subscription.
        <xref target="collection_example"/> presents an example for such a collection.
      </t>
      <figure anchor="collection_example" title="Example of collection from a device to Influx DB">
        <artwork><![CDATA[
     +------------+                +----------+
     |   MDT      |                |  Influx  |
     | Collector  |--------------> |   DB     |
     +------------+                +----------+
          ^
          |
          |
      +---------+
      | Device  |
      +---------+
          ]]></artwork>
      </figure>
      <t>
        In the scenario from <xref target="collection_example"/>, the collector receives MDT from the device and stores it into InfluxDB.
        We first present a version without data manifest and then how to enrich it with the data manifest.
      </t>
      <t>
        In InfluxDB, a datapoint is specified by giving the name of the measurement, zero or more key value entries named tags, one or more named values called fields and the timestamp for the datapoint.
        In our case a measurement could be "admin-status".
        The tags, whose aim to identify a particular instance of the measurement could be the name of the device and the name of the interface.
        The fields contain the values to store.
        InfluxDb defines a textual notation, named line protocol, to represent one datapoint per line.
        We use this line protocol in <xref target="influx_before"/> and <xref target="influx_after"/> to represent the way data could be fed to InfluxDB, omitting the timestamp for readability.
        See <eref target="https://docs.influxdata.com/influxdb/cloud/reference/syntax/line-protocol/"/> for more details.
      </t>
      <t>
        Without the data manifest, the MDT collector is likely to store something similar to <xref target="influx_before"/> in InfluxDB.
        In that case, only the value is stored, without any way to know how the value was obtained.
        <figure anchor="influx_before" title="Storing datapoints without data manifest">
            <artwork><![CDATA[
admin_status,device="PE1",interface="gig1" val=T
sent_bytes,device="PE1",interface="gig1" val=1234
            ]]></artwork>
        </figure>
      </t>
      <t>
        A possibility for keeping the data manifest with the data is to store it directly into InfluxDB.
        In that case, the collector can subscribe to the data exported by the module presented in this draft and store it inside influxDB.
        For the Platform Manifest, the collector subscribes to the path "ietf-platform-manifest:platform".
        For the Data Collection Manifest, assuming the subscription id is 42, the collector subscribes to the path "ietf-data-collection-manifest:data-collection/mdt-subscriptions[subscription-id=42]".
        The data, for instance serialized in JSON, can be stored in InfluxDB as shown in <xref target="influx_manifest"/> where "&lt;platform-manifest&gt;" and "&lt;data-manifest&gt;" represent the contents of respectively the Platform Manifest and the Data Collection Manifest.
        <figure anchor="influx_manifest" title="Storing data manifest">
          <artwork><![CDATA[
platform-manifest,device="PE1" val=<plaftorm-manifest>
collection-data-manifest,device="PE1",subId=42 val=<data-manifest>
            ]]></artwork>
        </figure>
      </t>
      <t>
        The link between a collected datapoint and the corresponding Platform Manifest is done via the common "device" tag.
        In order to link a datapoint with the corresponding Data Collection Manifest, the collector can add fields to specify where the Data Collection Manifest is located for that specific datapoint.
        For instance, the same datapoints as in <xref target="influx_before"/> could be stored as in <xref target="influx_after"/>, where "&lt;path&gt;" represents the path used for collecting the current datapoint.
        <figure anchor="influx_after" title="Storing datapoints with data manifest">
          <artwork><![CDATA[
admin_status,device="PE1",interface="gig1" val=T,subId=42,path=<path>
sent_bytes,device="PE1",interface="gig1" val=1234,subId=42,path=<path>
            ]]></artwork>
        </figure>
      </t>
      <t>
        In our simple example, from the "admin_status" datapoint, one can retrieve the corresponding Platform Manifest by looking at the last value for the "platform-manifest" measurement with the same value for the "device" tag.

        From the "admin-status" datapoint, one can retrieve the corresponding Data Collection Manifest by looking at the last value for the "data-manifest" measurement with tags "device" and "subId" matching respectively with the tag "device" and the field "subId" of the measurement.
        For that manifest, one can obtain information for the subscription and the specific information for the path by looking up the value of the "path" field in the "mdt-path-data-manifest" list.
      </t>

    </section>
    <section title="Changes between revisions">
      <t>
        v05 -> v06
        <list>
          <t> Remove YANG packages </t>
          <t> Switch YANG models from device view to network view </t>
          <t> Add PEN number to identify vendors </t>
        </list>
      </t>
      <t>
        v04 -> v05
        <list>
          <t> First version of example scenario</t>
          <t> Updated affiliation</t>
          <t> Updated YANG module names to ietf-platform-manifest and ietf-data-collection-manifest </t>
          <t> Unify used terms as defined in the terminology section</t>
          <t> Replaced 'device' with 'platform' </t>
          <t> Split Section 5 into two sections for better readibility</t>
        </list>
      </t>
      <t>
        v03 -> v04
        <list>
          <t> Fix xym error</t>
          <t> Moved terminology after introduction</t>
          <t> Clarified the role of the module</t>
        </list>
      </t>
      <t>
        v02 -> v03
        <list>
          <t> Add when clause in YANG model</t>
          <t> Fix validation errors on YANG modules</t>
          <t> Augment YANG library to handle semantic versioning</t>
        </list>
      </t>
      <t>
        v01 -> v02
        <list>
          <t> Alignment with YANGCatalog YANG module: name, vendor </t>
          <t> Clarify the use of YANG instance file </t>
          <t> Editorial improvements </t>
          <t> </t>
        </list>
      </t>
      <t>
        v00 -> v01
        <list>
          <t> Adding more into data platform: yang packages, whole yanglib module to specify datastores </t>
          <t> Setting the right type for periods: int64 -> uint64 </t>
          <t> Specify the origin datastore for mdt subscription </t>
          <t> Set both models to config false </t>
          <t> Applying text comments from Mohamed Boucadair </t>
          <t> Adding an example of data-manifest file </t>
          <t> Adding rationale for reusing telemetry system for collection of the manifests </t>
          <t> Export manifest with on change telemetry as opposed to YANG instance file </t>
          <t> </t>
        </list>
      </t>
      <t>
        v00
          <list>
          <t> Initial version </t>
          <t> </t>
        </list>
      </t>
    </section>
    <section title="Acknowledgements" numbered="no">
      <t>
          Thanks to Mohamed Boucadair and Tianran Zhou for their reviews and comments.
       </t>
    </section>
  </back>
</rfc>
<!-- Local Variables: -->
<!-- fill-column:72 -->
<!-- End: -->